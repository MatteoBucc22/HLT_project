{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fc40c8",
   "metadata": {
    "id": "75fc40c8"
   },
   "source": [
    "# Paraphrase Italian Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155d2c8",
   "metadata": {
    "id": "3155d2c8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a67881",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "b7a67881",
    "outputId": "731cd36b-8324-42a6-cc19-739bab2e3301"
   },
   "outputs": [],
   "source": [
    "# Use 'skip' to skip problematic lines and continue parsing\n",
    "df = pd.read_csv('PACCSS-IT.txt', sep='\\t', usecols=range(7), quoting=3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90672ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a90672ca",
    "outputId": "612f652e-f5db-46e0-8630-b129b6c754ae"
   },
   "outputs": [],
   "source": [
    "min_confidence = df['Confidence'].min()\n",
    "max_confidence = df['Confidence'].max()\n",
    "min_cosine = df['Cosine_Similarity'].min()\n",
    "max_cosine = df['Cosine_Similarity'].max()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Confidence range: {min_confidence} to {max_confidence}\")\n",
    "print(f\"Cosine Similarity range: {min_cosine} to {max_cosine}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc88599",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8cc88599",
    "outputId": "baff0949-ead7-4ff7-d37d-b9d97f348c5d"
   },
   "outputs": [],
   "source": [
    "# drop the last three columns\n",
    "df = df.iloc[:, :-3]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427ccff",
   "metadata": {},
   "source": [
    "Fix a threshold for cosine and confidence to filter the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ebf8f",
   "metadata": {
    "id": "605ebf8f"
   },
   "outputs": [],
   "source": [
    "confidence_treshold = 0.90\n",
    "cosine_threshold = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215ffb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c215ffb5",
    "outputId": "4790c040-6399-4e6c-c3f6-35929f91dd2f"
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame based on the thresholds\n",
    "filtered_df = df[(df['Confidence'] >= confidence_treshold) & (df['Cosine_Similarity'] >= cosine_threshold)]\n",
    "\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ff8aa",
   "metadata": {},
   "source": [
    "These are our positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07643b1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07643b1e",
    "outputId": "24268ec2-52ef-43ed-ec26-6ecfa3b3e494"
   },
   "outputs": [],
   "source": [
    "# add a column label with value 1\n",
    "filtered_df.loc[:, 'label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb4f059",
   "metadata": {},
   "source": [
    "The following code splits our dataset into train, validation, and test sets and check if there are overlapping samples between the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc153645",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc153645",
    "outputId": "24874a3f-ba8d-419f-fd18-ae2df03e0676"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train val test split 60/20/20\n",
    "train_val_df, test_df = train_test_split(filtered_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)\n",
    "\n",
    "# check that sentences (not just pairs) are disjoint between train/val/test; if not, remove offending rows\n",
    "\n",
    "def get_sentences(df):\n",
    "    return set(df['Sentence_1']).union(set(df['Sentence_2']))\n",
    "\n",
    "train_sentences = get_sentences(train_df)\n",
    "val_sentences = get_sentences(val_df)\n",
    "test_sentences = get_sentences(test_df)\n",
    "\n",
    "# find overlaps\n",
    "overlap_train_val = train_sentences & val_sentences\n",
    "overlap_train_test = train_sentences & test_sentences\n",
    "overlap_val_test = val_sentences & test_sentences\n",
    "\n",
    "# remove rows with overlapping sentences\n",
    "def remove_overlaps(df, forbidden_sentences):\n",
    "    mask = ~df['Sentence_1'].isin(forbidden_sentences) & ~df['Sentence_2'].isin(forbidden_sentences)\n",
    "    return df[mask]\n",
    "\n",
    "# iteratively remove overlaps until all sets are disjoint\n",
    "while True:\n",
    "    train_sentences = get_sentences(train_df)\n",
    "    val_sentences = get_sentences(val_df)\n",
    "    test_sentences = get_sentences(test_df)\n",
    "\n",
    "    overlap_train_val = train_sentences & val_sentences\n",
    "    overlap_train_test = train_sentences & test_sentences\n",
    "    overlap_val_test = val_sentences & test_sentences\n",
    "\n",
    "    if not (overlap_train_val or overlap_train_test or overlap_val_test):\n",
    "        break\n",
    "\n",
    "    if overlap_train_val:\n",
    "        val_df = remove_overlaps(val_df, overlap_train_val)\n",
    "        train_df = remove_overlaps(train_df, overlap_train_val)\n",
    "    if overlap_train_test:\n",
    "        test_df = remove_overlaps(test_df, overlap_train_test)\n",
    "        train_df = remove_overlaps(train_df, overlap_train_test)\n",
    "    if overlap_val_test:\n",
    "        test_df = remove_overlaps(test_df, overlap_val_test)\n",
    "        val_df = remove_overlaps(val_df, overlap_val_test)\n",
    "\n",
    "# reset indices\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# recalculate the split sizes\n",
    "train_size = len(train_df)\n",
    "val_size = len(val_df)\n",
    "test_size = len(test_df)\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Validation size: {val_size}\")\n",
    "print(f\"Test size: {test_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc2e8e",
   "metadata": {},
   "source": [
    "We generate the negative samples by randomly sampling sentences from the dataset and pairing them with sentences from the same dataset using the cosine similarity score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dfdb68",
   "metadata": {
    "id": "f6dfdb68"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "threshold = 0.45\n",
    "\n",
    "def generate_negative_samples(split_df):\n",
    "    sentences_1 = split_df['Sentence_1'].unique()\n",
    "    sentences_2 = split_df['Sentence_2'].unique()\n",
    "    negative_df = pd.DataFrame(columns=['Sentence_1', 'Sentence_2', 'Cosine_Similarity', 'label'])\n",
    "    # Generate negative samples to achieve a 1:2 positive:negative ratio\n",
    "    num_positive = len(split_df[split_df['label'] == 1])\n",
    "    num_negative_needed = num_positive * 2\n",
    "    while len(negative_df) < num_negative_needed:\n",
    "        s1 = np.random.choice(sentences_1)\n",
    "        s2 = np.random.choice(sentences_2)\n",
    "        if s1 == s2:\n",
    "            continue\n",
    "        # Check if pair exists in positive samples\n",
    "        if not (((split_df['Sentence_1'] == s1) & (split_df['Sentence_2'] == s2)).any() or\n",
    "                ((split_df['Sentence_1'] == s2) & (split_df['Sentence_2'] == s1)).any()):\n",
    "            # Check if pair already generated\n",
    "            if not (((negative_df['Sentence_1'] == s1) & (negative_df['Sentence_2'] == s2)).any() or\n",
    "                    ((negative_df['Sentence_1'] == s2) & (negative_df['Sentence_2'] == s1)).any()):\n",
    "                emb_s1 = model.encode(s1)\n",
    "                emb_s2 = model.encode(s2)\n",
    "                cosine_similarity = model.similarity(emb_s1, emb_s2)\n",
    "                if cosine_similarity < threshold:\n",
    "                    row = pd.DataFrame([{'Sentence_1': s1, 'Sentence_2': s2, 'Cosine_Similarity': cosine_similarity, 'label': 0}])\n",
    "                    negative_df = pd.concat([negative_df, row], ignore_index=True)\n",
    "    return negative_df\n",
    "\n",
    "train_df = pd.concat([train_df, generate_negative_samples(train_df)], ignore_index=True)\n",
    "train_df = shuffle(train_df, random_state=42).reset_index(drop=True)\n",
    "\n",
    "val_df = pd.concat([val_df, generate_negative_samples(val_df)], ignore_index=True)\n",
    "val_df = shuffle(val_df, random_state=42).reset_index(drop=True)\n",
    "\n",
    "test_df = pd.concat([test_df, generate_negative_samples(test_df)], ignore_index=True)\n",
    "test_df = shuffle(test_df, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# mantain only Sentence_1, Sentence_2, label columns\n",
    "train_df = train_df[['Sentence_1', 'Sentence_2', 'label']]\n",
    "val_df = val_df[['Sentence_1', 'Sentence_2', 'label']]\n",
    "test_df = test_df[['Sentence_1', 'Sentence_2', 'label']]\n",
    "\n",
    "# save the dataframes to csv\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "val_df.to_csv('val.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292c4ff",
   "metadata": {},
   "source": [
    "Check for final possible overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4fc8f",
   "metadata": {
    "id": "aab4fc8f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load(path):  \n",
    "    df = pd.read_csv(path)  \n",
    "    # crea coppie ordinate e unordered\n",
    "    pairs = set(zip(df.Sentence_1, df.Sentence_2))\n",
    "    upairs = set(frozenset([s1,s2]) for s1,s2 in pairs)\n",
    "    return df, pairs, upairs\n",
    "\n",
    "train, train_pairs, train_up = load(\"train.csv\")\n",
    "val,   val_pairs,   val_up   = load(\"val.csv\")\n",
    "test,  test_pairs,  test_up  = load(\"test.csv\")\n",
    "\n",
    "def inter(a, b):\n",
    "    return len(a & b)\n",
    "\n",
    "print(\"== Pair-level overlap ==\")\n",
    "print(f\"train ∩ test  (ordered):     {inter(train_pairs, test_pairs)}\")\n",
    "print(f\"train ∩ val   (ordered):     {inter(train_pairs, val_pairs)}\")\n",
    "print(f\"val   ∩ test  (ordered):     {inter(val_pairs, test_pairs)}\")\n",
    "\n",
    "print(f\"train ∩ test  (unordered):   {inter(train_up, test_up)}\")\n",
    "print(f\"train ∩ val   (unordered):   {inter(train_up, val_up)}\")\n",
    "print(f\"val   ∩ test  (unordered):   {inter(val_up, test_up)}\")\n",
    "\n",
    "print(\"\\n== Sentence-level overlap ==\")\n",
    "s_train = set(train.Sentence_1).union(train.Sentence_2)\n",
    "s_val   = set(val.Sentence_1).union(val.Sentence_2)\n",
    "s_test  = set(test.Sentence_1).union(test.Sentence_2)\n",
    "print(f\"sentences train ∩ test:       {len(s_train & s_test)}\")\n",
    "print(f\"sentences train ∩ val:        {len(s_train & s_val)}\")\n",
    "print(f\"sentences val   ∩ test:       {len(s_val   & s_test)}\")\n",
    "\n",
    "print(\"\\n== Duplicati interni ==\")\n",
    "print(f\"train dup ordered:   {len(train) - len(train_pairs)}\")\n",
    "print(f\"val   dup ordered:   {len(val)   - len(val_pairs)}\")\n",
    "print(f\"test  dup ordered:   {len(test)  - len(test_pairs)}\")\n",
    "\n",
    "print(\"\\n== Label distribution ==\")\n",
    "for name, df in [(\"train\", train), (\"val\", val), (\"test\", test)]:\n",
    "    print(f\"{name}:\")\n",
    "    print(df.label.value_counts(normalize=True), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370ed22",
   "metadata": {},
   "source": [
    "The following section trains a logistic classifier. It is used to validate the idea that our dataset is too simple to be used with UmBERTo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640ade94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "val = pd.read_csv(\"val.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f42d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "best params: {'feats__word__max_df': 0.9, 'feats__word__min_df': 2, 'feats__word__ngram_range': (1, 2), 'feats__word__sublinear_tf': True, 'lr__C': 10, 'lr__penalty': 'l2', 'lr__solver': 'liblinear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      1530\n",
      "           1       0.89      0.93      0.91      1530\n",
      "\n",
      "    accuracy                           0.91      3060\n",
      "   macro avg       0.91      0.91      0.91      3060\n",
      "weighted avg       0.91      0.91      0.91      3060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# prepare text data by concatenating the two sentences\n",
    "X_train_text = train['Sentence_1'] + ' ' + train['Sentence_2']\n",
    "y_train       = train['label']\n",
    "X_test_text  = test['Sentence_1'] + ' ' + test['Sentence_2']\n",
    "y_test        = test['label']\n",
    "\n",
    "# potenziamento TF–IDF con word- e char-gram\n",
    "word_tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    ngram_range=(1,3),\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "char_tfidf = TfidfVectorizer(\n",
    "    analyzer='char_wb',\n",
    "    ngram_range=(2,5),\n",
    "    min_df=1,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "feats = FeatureUnion([('word', word_tfidf), ('char', char_tfidf)])\n",
    "\n",
    "# pipeline con LogisticRegression su feature union\n",
    "pipe = Pipeline([\n",
    "    ('feats', feats),\n",
    "    ('lr', LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feats__word__ngram_range':  [(1,2), (1,3)],\n",
    "    'feats__word__min_df':       [1, 2],\n",
    "    'feats__word__max_df':       [0.9],\n",
    "    'feats__word__sublinear_tf': [True],\n",
    "    'lr__C':                     [0.1, 1, 10],\n",
    "    'lr__penalty':               ['l2'],\n",
    "    'lr__solver':                ['liblinear']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_text, y_train)\n",
    "\n",
    "print('best params:', grid.best_params_)\n",
    "y_pred = grid.predict(X_test_text)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
